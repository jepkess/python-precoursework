{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkARziB3XwDqoU9DchtfmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jepkess/python-precoursework/blob/master/Assignment_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 1\n",
        "CIFAR-10 is a dataset that is widely used in the field of computer vision and machine learning. The data is arranged in low resolution images with 32pixel height and 32pixel width that are then grouped into classes, ‘airplane’, ‘automobile, ‘bird’, ‘cat’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. These datasets store the data samples and their corresponding labels.\n",
        "The process of image classification takes a number of steps so as to guarantee accuracy in the end."
      ],
      "metadata": {
        "id": "RmVi6ZzDaLTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary pytorch tools\n",
        "Import torch\n",
        "Import torchdivision\n",
        "Import torchvision.transforms as transforms\n",
        "Import torch.nn as nn\n",
        "Import torch.optim as optim as optim\n",
        "# load and preprocess the CIFAR-10 dataset\n",
        " transform = transforms.Component ([\n",
        "                        transforms.ToTensor(),\n",
        "                      transforms,Normalize(( 0.5,   0.5,   0.5),  (0.5,  0.5,  0.5))\n",
        " ])\n",
        "trainset = torchdivision,datasets.CIFAR10( root= ‘./data’ , train=True, doeload=True, transform=transform)\n",
        "trainloader =torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=false)\n",
        "# define the LeNet-style architecture\n",
        "Class Net(nn.Module):\n",
        "        # …..\n",
        "#training loop\n",
        "Best_accuracy = 0.0\n",
        "For epoch in range(num_epochs):\n",
        "      # …\n",
        "# Print the accuracy obtained from the code above\n",
        "Print(f “Training finished. Best accuracy: {best_accuracy%”}"
      ],
      "metadata": {
        "id": "RDdOmbXqi0Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and normalizing the CIFAR-10 datasets on to the torch vision.\n",
        "This is an easy process that transforms torch vision datasets to datasets that are referred as PILImages. The transforms are used to manipulate data.  The PILImages are then transformed to Tensors that are of a normalized range that is more suitable for training machine learning algorithms.\n",
        "Tensors are a special type of data that is used in PyTorch to convert the inputs and outputs of a model. Its underlying memory eliminates the need to copy data and also allow automatic differentiation of data using an in-built differentiation engine called torch.autograd.\n"
      ],
      "metadata": {
        "id": "ZAgRVck_Z8iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data argumentation transforms\n",
        "augumemtation_transforms = transforms.Compose([\n",
        "           transforms.RandomHorizontal1Flip(),\n",
        "           transforms.RandomRotation(10),\n",
        "           transforms.ColorJitter(brightness=0.3, contrast=0.2,  saturation=0.2, hue=0.2),\n",
        "           transforms.RandomAffine(0, translate=(0.2, 0.3)),\n",
        "           transforms.RandomApply([transforms.GaussianBlur(kernel_size=6)], p=0.2),\n",
        "           transforms.ToTensor(),\n",
        "           transforms.Normalize((1.0, 1.0, 1.0), (1.0, 1.0, 1.0)),\n",
        "])\n",
        "# Augment the training dataset\n",
        "   augmented_trainset = torchdivision. Datasets.CIFAR10(root=’/data’,train=True,     download=True, transform=augmentation_transform)\n",
        "   augmented_trainloader = torch. Utils.data.DataLoader(augmented_trainset) , batch_size=64, shuffle=True)\n",
        "\n",
        "# …\n",
        "#The performance improvement\n",
        "print(f”Accuracy with data augmentation:[ Improved Accuracy]%”)\n"
      ],
      "metadata": {
        "id": "Ic90BgKqbQ_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET python script"
      ],
      "metadata": {
        "id": "CljYCGLAcFOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Resnet model from torchdivision\n",
        "   from torchdivion.models import resnet17\n",
        "\n",
        "# modify the resnet model to fit the CIFAR-10 dataset\n",
        "  Class CustomResnet(nn.Module):\n",
        "           def __init__(self):\n",
        "                 super(CustomResnet17, self).__()\n",
        "                 self.resnet = resnet17(pretrained=False)\n",
        "            # modify tha final layer to have 15 outputs\n",
        "                  self.resnet.fc= nn.linear(512, 15)\n",
        "\n",
        "           def forward(self, x):\n",
        "                 return self.resnet(x)\n",
        "\n",
        "# …\n",
        "# Report for the final performance\n",
        "  print(f”Accuracy of the custom Resnet: [Resnet Accuracy]%”)\n"
      ],
      "metadata": {
        "id": "occ7dirqd2op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 2\n",
        "GANs are shown real pictures that create images that are now regarded as the real images and any other image that is just close but not the exact image is regarded as fake image.\n",
        "The GANs overtime have been so useful in a good number of ways which may include; the high ability to create images that are so easy to identify compared to the real photographs, a technique that has greatly favored the art and entertainment industry.\n"
      ],
      "metadata": {
        "id": "oaC3K0f_eCbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  From PIL import Image, ImageDraw\n",
        "  import os\n",
        "  import random\n",
        " # Function to create a colored square image with random properties\n",
        "    def create_colored_square(size, color, position):\n",
        "    img= Image.new(‘RGB’, size, (0, 0, 0)) # black background\n",
        "    draw = ImageDraw.Draw()img\n",
        "    draw.rectangle(position, fill=color)\n",
        "      return img\n",
        "\n",
        "\n",
        "# Function to save the images to class-specific subfolders\n",
        "    def save_imags(image, class_name, image_count):\n",
        "    folder_path = os.path.join(“dataset”, class_name)\n",
        "    os.makerdirs(folder_path, esist_ok=True)\n",
        "    image_path =os.path.join(folder_path , f’{class_name}_{image_count}.png”)\n",
        "    image.save(image_path, “PNG”)\n",
        "\n",
        "# create the dataset now\n",
        "   dataset_size = 1200  # number of images in the dataset\n",
        "   colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]  # red , green . blue\n",
        "   min_square_size = 10\n",
        "   max_square_size = 30\n",
        "   min_position = 10\n",
        "   max¬_position =56\n",
        "\n",
        "for i in range(dataset_size):\n",
        "        # randomly choose color, size and position for the squares\n",
        "         Color = random.choice(colors)\n",
        "         size = (random.randint(min_square_size, max_square_size), random.randint(min_square_size, max_square_size))\n",
        "           position = (\n",
        "                random.randint(min_position, max_position),\n",
        "                random.randint(min_position, max_position),\n",
        "                random.randint(min_position, max_position),\n",
        "                random.randint(min_position, max_position),\n",
        "           )\n",
        "         # Create the colored square image\n",
        "           class_name = f”square_{i  % len(colors)}”\n",
        "           save_image(square_image, class_name, i)\n",
        "  print(“Data generation done.”)\n"
      ],
      "metadata": {
        "id": "GHvtAzQHfE-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VlhSebQ_fgrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DCGAN (Deep Convolutional GAN)\n",
        "This is a generative adverse network architecture that acts as an extension to the GAN. The DCGAN is majorly designed to support the task of creating high quality images. This is made possible through the presence of the convolutional neural networks that are planted in the generator and the discriminator. All this work is geared to the creation of effective image data generations.\n",
        "One thing about the DCGANs is that there no fully connected layers of either the convolutional or the transposed convolutional layers, this is to allow it to store a wide range of information.\n"
      ],
      "metadata": {
        "id": "p0N0p6iBhs3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        import torch\n",
        "        import torch.nn as nn\n",
        "        from torchdivision import datasets, transforms\n",
        "        from torch.utils.data impot DataLoader\n",
        "        import torchdivision.utils as vutils\n",
        "        import os\n",
        "\n",
        "        # set random seed for reproduction\n",
        "        manual_seed = 42\n",
        "        torch.manual_ seed(manual_seed)\n",
        "\n",
        "       # Hyperparameters\n",
        "      Batch_size = 62\n",
        "      image_size = 62\n",
        "      nz = 100\n",
        "      ngf =  62\n",
        "      ndf  = 62\n",
        "      num_epochs = 100\n",
        "      learning_rate = 0.0003\n",
        "      betal = 0.5\n",
        "\n",
        "# define the generator network\n",
        " class Generator(nn.Module):\n",
        "       def __init__(self):\n",
        "            super(Generator, self). __init__()\n",
        "             self.main = nn.Sequential (\n",
        "             nn.Conv2d( 3, ndf, 4, 2, 1, bias=False),\n",
        "             nn.LeakeyReLU(0.2, inplace=True),\n",
        "             nn.Conv2d(ndf, ndf *2, 4, 2, 1, bias=False),\n",
        "             nn.BatchNorm2d(ndf * 2),\n",
        "             nn.leakyReLU(0.2, inplace=True),\n",
        "             nn.Conv2d(ndf * 2, ndf *4,  4,  2, 1, bias=False),\n",
        "             nn.BatchNorm2d( ndf * 4),\n",
        "             nn.LeakyReLU(0.2, inplace=True),\n",
        "             nn.conv2d(ndf  * 4, 1, 4, 1, 0, bias=False),\n",
        "             nn.Sigmoid()\n",
        "      )\n",
        "def forward(self, input):\n",
        "       return self.main(input)\n",
        "\n",
        "# create Generator and discriminator\n",
        "netG = Generator()\n",
        "netD = Diascriminator()\n",
        "\n",
        "#define loss function and optimizes\n",
        "criterion = nn.BCELoss()\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
        "\n",
        "# load the dataset\n",
        "Dataset = datasets.ImageFolder(root=”dataset”, transform=transforms,Compose([\n",
        "           transforms.Resize(image_size),\n",
        "           transforms.CenterCrop(image_size),\n",
        "           transforms.ToTensor(),\n",
        "           transforms,Normalize((0,5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]))\n",
        "Dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# create a directory to save generated images\n",
        " os.makedirs(“generated_images” ,  exists_ok=True)\n",
        "\n",
        "\n",
        "# training loop\n",
        "  for epoch in range(num_epochs):\n",
        "   for i, data in enumerates(dataloader, 0):\n",
        "   #update discriminator network\n",
        "         netD.zero_grad()\n",
        "          real_data = data[0].to(“cuda”)\n",
        "          batch_size_curr = real_data.size(0)\n",
        "          label = torch.full((batch_size_curr,), 1, device=”cuda”)\n",
        "          output = netdD(real_data).view(-1)\n",
        "           errD_fake = criterion(output, label)\n",
        "           errD_fake.backward()\n",
        "           D_G_z1 = output.mean().item()\n",
        "           errD = errD_real + errD_fake\n",
        "           optimizerD.step()\n",
        "\n",
        "    # update generator network\n",
        "      netD.zero_grad()\n",
        "      label.fill_(1)\n",
        "      output = netD(fake_data).view(-1)\n",
        "      errG = criterion (output, label)\n",
        "      errG.backward()\n",
        "      D_G_z2 = output.mean().item()\n",
        "      optimizerG.step()\n",
        "\n",
        "    # print training stats\n",
        "     if i % 45 == 0:\n",
        "          print(f”[{epoch}/{num_epochs}] [{i}/{len(dataloader)}]”\n",
        "                    f”loss_D: {errD.item():.4f} loss_G: {errG.item():.4f}”\n",
        "                    f”D(x): {D_x: .4f} D((z)): {D_G_z1:.4f}/{D_G_z2: .4f}” )\n",
        "\n",
        "      #save generated images at the end of each epoch\n",
        "       with torch,no_grad():\n",
        "              take = etG(fixed_noise).detach().cpu\n",
        "        vutils,save_save_image(fake, f”generated_images/fake_{epoch}.png”, normalize=True)\n",
        "     print(“Training done”)\n"
      ],
      "metadata": {
        "id": "KYUyq4sniBAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QEUjTcr-iU77"
      }
    }
  ]
}